{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import featuretools as ft\n",
    "\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from itertools import combinations\n",
    "\n",
    "from dask import bag\n",
    "from dask.diagnostics import ProgressBar\n",
    "from featuretools.primitives import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_entityset(filename, target_entity):\n",
    "    df = pd.read_hdf(filename)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df['id'] = df.index\n",
    "    df['hour'] = df['click_time'].dt.hour\n",
    "\n",
    "    es = ft.EntitySet(id='clicks')\n",
    "    es = es.entity_from_dataframe(\n",
    "        entity_id='clicks',\n",
    "        dataframe=df,\n",
    "        index='id',\n",
    "        time_index='click_time',\n",
    "        variable_types={\n",
    "            'ip': ft.variable_types.Categorical,\n",
    "            'app': ft.variable_types.Categorical,\n",
    "            'device': ft.variable_types.Categorical,\n",
    "            'os': ft.variable_types.Categorical,\n",
    "            'channel': ft.variable_types.Categorical,\n",
    "            'is_attributed': ft.variable_types.Boolean,\n",
    "        }\n",
    "    )\n",
    "    es = es.normalize_entity(base_entity_id='clicks', new_entity_id=target_entity, index=target_entity, make_time_index=False)\n",
    "#     es = es.normalize_entity(base_entity_id='clicks', new_entity_id='hour', index='hour', make_time_index=False)\n",
    "    es.add_last_time_indexes()\n",
    "    return es\n",
    "\n",
    "def calc_feature_matrix(es, target_entity, cutoff_time, training_window):\n",
    "    feature_matrix, _ = ft.dfs(\n",
    "        entityset=es,\n",
    "        target_entity=target_entity,\n",
    "        trans_primitives=[],\n",
    "#         agg_primitives=[Count, AvgTimeBetween, Trend, NUnique, Skew, Std, Median],\n",
    "        agg_primitives=[Count, AvgTimeBetween, NUnique],\n",
    "#         cutoff_time=cutoff_time,\n",
    "#         training_window=training_window,\n",
    "        max_features=-1,\n",
    "        max_depth=4\n",
    "    )\n",
    "\n",
    "    return feature_matrix\n",
    "\n",
    "\n",
    "def create_features(entity_sets, target_entity, cutoff_time, training_window):\n",
    "    tw_suffix = training_window.get_name().replace(' ', '').lower()\n",
    "\n",
    "    feature_matrices = entity_sets.map(\n",
    "        calc_feature_matrix,\n",
    "        target_entity=target_entity,\n",
    "        cutoff_time=cutoff_time,\n",
    "        training_window=training_window)\n",
    "    out = feature_matrices.compute()\n",
    "    feature_matrix = pd.concat(out)\n",
    "#     feature_matrix = feature_matrix[[c for c in feature_matrix.columns if c in to_select]]\n",
    "    feature_matrix.columns = [str(col) + f\"_{target_entity}_{tw_suffix}\" for col in feature_matrix.columns]\n",
    "\n",
    "    del out, feature_matrices\n",
    "    gc.collect()\n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_entities_init = ['app', 'device', 'os', 'channel', 'ip', 'hour']\n",
    "target_entities = []\n",
    "\n",
    "for t in combinations(target_entities_init, 1):\n",
    "    if 'device' in t: continue\n",
    "    target_entities.append(t[0])\n",
    "for t in combinations(target_entities_init, 2):\n",
    "    if 'ip' in t: continue\n",
    "    target_entities.append(list(t))\n",
    "for t in combinations(target_entities_init, 3):\n",
    "    if 'ip' in t: continue\n",
    "#      target_entities.append(list(t))\n",
    "# for t in combinations(target_entities_init, 4):\n",
    "#     target_entities.append(list(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing app\n",
      "Writing ../data/interim/features/app/features_2017-11-10_1700_7days_countall.hdf.compress\n",
      "Processing os\n",
      "Writing ../data/interim/features/os/features_2017-11-10_1700_7days_countall.hdf.compress\n",
      "Processing channel\n",
      "Writing ../data/interim/features/channel/features_2017-11-10_1700_7days_countall.hdf.compress\n",
      "Processing ip\n",
      "Writing ../data/interim/features/ip/features_2017-11-10_1700_7days_countall.hdf.compress\n",
      "Processing hour\n",
      "Writing ../data/interim/features/hour/features_2017-11-10_1700_7days_countall.hdf.compress\n",
      "Processing app_device\n",
      "Writing ../data/interim/features/app_device/features_2017-11-10_1700_7days_countall.hdf.compress\n",
      "Processing app_os\n",
      "Writing ../data/interim/features/app_os/features_2017-11-10_1700_7days_countall.hdf.compress\n",
      "Processing app_channel\n",
      "Writing ../data/interim/features/app_channel/features_2017-11-10_1700_7days_countall.hdf.compress\n",
      "Processing app_hour\n",
      "Writing ../data/interim/features/app_hour/features_2017-11-10_1700_7days_countall.hdf.compress\n",
      "Processing device_os\n",
      "Writing ../data/interim/features/device_os/features_2017-11-10_1700_7days_countall.hdf.compress\n",
      "Processing device_channel\n",
      "Writing ../data/interim/features/device_channel/features_2017-11-10_1700_7days_countall.hdf.compress\n",
      "Processing device_hour\n",
      "Writing ../data/interim/features/device_hour/features_2017-11-10_1700_7days_countall.hdf.compress\n",
      "Processing os_channel\n",
      "Writing ../data/interim/features/os_channel/features_2017-11-10_1700_7days_countall.hdf.compress\n",
      "Processing os_hour\n",
      "Writing ../data/interim/features/os_hour/features_2017-11-10_1700_7days_countall.hdf.compress\n",
      "Processing channel_hour\n",
      "Writing ../data/interim/features/channel_hour/features_2017-11-10_1700_7days_countall.hdf.compress\n"
     ]
    }
   ],
   "source": [
    "# target_entities = ['app']\n",
    "feature_name_suffix = 'countall'\n",
    "# training_windows = ['1 hour', '1 day']\n",
    "training_windows = ['7 days']\n",
    "\n",
    "cutoff_time=datetime.datetime(2017, 11, 10, 17, 0)\n",
    "\n",
    "for target_entity in target_entities:\n",
    "    target_entity_name = target_entity if type(target_entity) == str else \"_\".join(target_entity)\n",
    "    print(f\"Processing {target_entity_name}\")\n",
    "    features_dir = f\"../data/interim/features/{target_entity_name}\"\n",
    "    if not os.path.exists(features_dir): os.makedirs(features_dir)\n",
    "    filenames = glob(f\"../data/interim/partitioned_all/{target_entity_name}/train_*.hdf.compress\")\n",
    "    b = bag.from_sequence(filenames)\n",
    "    entity_sets = b.map(create_entityset, target_entity_name)\n",
    "\n",
    "    for training_window in training_windows:\n",
    "        tw_suffix = training_window.replace(' ', '').lower()\n",
    "        feature_matrix = create_features(entity_sets, target_entity=target_entity_name, cutoff_time=cutoff_time, training_window=ft.Timedelta(training_window))\n",
    "\n",
    "        output_file = f\"{features_dir}/features_{cutoff_time.strftime('%Y-%m-%d_%H%M')}_{tw_suffix}_{feature_name_suffix}.hdf.compress\"\n",
    "        print(f\"Writing {output_file}\")\n",
    "        feature_matrix.to_hdf(output_file, 'features', mode='w', complib='blosc', fletcher32=True, complevel=9)\n",
    "        del feature_matrix\n",
    "        gc.collect()\n",
    "        \n",
    "    del b, entity_sets\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf(\"../data/interim/features/app/features_2017-11-10_1500_7days_countall.hdf.compress\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['COUNT(clicks)_app_7days',\n",
       "       'AVG_TIME_BETWEEN(clicks.click_time)_app_7days',\n",
       "       'NUM_UNIQUE(clicks.ip)_app_7days',\n",
       "       'NUM_UNIQUE(clicks.device)_app_7days',\n",
       "       'NUM_UNIQUE(clicks.os)_app_7days',\n",
       "       'NUM_UNIQUE(clicks.channel)_app_7days'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
