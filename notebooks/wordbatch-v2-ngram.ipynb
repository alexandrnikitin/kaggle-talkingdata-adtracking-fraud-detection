{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo pip install git+https://github.com/anttttti/Wordbatch.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wordbatch\n",
    "from wordbatch.extractors import WordHash\n",
    "from wordbatch.models import FM_FTRL\n",
    "# from wordbatch.data_utils import *\n",
    "import threading\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'ip': 'uint32',\n",
    "    'app': 'uint16',\n",
    "    'device': 'uint16',\n",
    "    'os': 'uint16',\n",
    "    'channel': 'uint16',\n",
    "    'is_attributed': 'uint8'\n",
    "}\n",
    "\n",
    "train_filenames = [\n",
    "    '../data/interim/combined/train_2017-11-07_1700_08_1600_0_attributed.csv.gz',\n",
    "    '../data/interim/combined/train_2017-11-07_1700_08_1600_1_attributed.csv.gz',\n",
    "    '../data/interim/combined/train_2017-11-07_1700_08_1600_2_attributed.csv.gz',\n",
    "    '../data/interim/combined/train_2017-11-07_1700_08_1600_3_attributed.csv.gz',\n",
    "    '../data/interim/combined/train_2017-11-07_1700_08_1600_4_attributed.csv.gz',\n",
    "    '../data/interim/combined/train_2017-11-07_1700_08_1600_5_attributed.csv.gz',\n",
    "    '../data/interim/combined/train_2017-11-07_1700_08_1600_6_attributed.csv.gz',\n",
    "    '../data/interim/combined/train_2017-11-07_1700_08_1600_7_attributed.csv.gz',\n",
    "    '../data/interim/combined/train_2017-11-07_1700_08_1600_8_attributed.csv.gz',\n",
    "    '../data/interim/combined/train_2017-11-07_1700_08_1600_9_attributed.csv.gz',\n",
    "]\n",
    "\n",
    "validate_filename = '../data/interim/combined/train_2017-11-09_0400_attributed.csv.gz'\n",
    "\n",
    "\n",
    "categorical_features = [\n",
    "    'app', 'device', 'os', 'channel',\n",
    "    'MODE(clicks.ip)_app_1day',\n",
    "    'MODE(clicks.device)_app_1day',\n",
    "    'MODE(clicks.os)_app_1day',\n",
    "    'MODE(clicks.channel)_app_1day',\n",
    "    'MODE(clicks.ip WHERE is_attributed = True)_app_1day',\n",
    "    'MODE(clicks.device WHERE is_attributed = True)_app_1day',\n",
    "    'MODE(clicks.os WHERE is_attributed = True)_app_1day',\n",
    "    'MODE(clicks.channel WHERE is_attributed = True)_app_1day',\n",
    "    'MODE(clicks.HOUR(click_time))_app_1day',\n",
    "    'MODE(clicks.HOUR(click_time) WHERE is_attributed = True)_app_1day',\n",
    "    'MODE(clicks.ip)_device_1day',\n",
    "    'MODE(clicks.app)_device_1day',\n",
    "    'MODE(clicks.os)_device_1day',\n",
    "    'MODE(clicks.channel)_device_1day',\n",
    "    'MODE(clicks.ip WHERE is_attributed = True)_channel_1day',\n",
    "    'MODE(clicks.app WHERE is_attributed = True)_channel_1day',\n",
    "    'MODE(clicks.device WHERE is_attributed = True)_channel_1day',\n",
    "    'MODE(clicks.os WHERE is_attributed = True)_channel_1day',\n",
    "    'MODE(clicks.HOUR(click_time))_channel_1day',\n",
    "    'MODE(clicks.HOUR(click_time) WHERE is_attributed = True)_channel_1day',\n",
    "    'MODE(clicks.ip WHERE is_attributed = True)_device_1day',\n",
    "    'MODE(clicks.app WHERE is_attributed = True)_device_1day',\n",
    "    'MODE(clicks.os WHERE is_attributed = True)_device_1day',\n",
    "    'MODE(clicks.channel WHERE is_attributed = True)_device_1day',\n",
    "    'MODE(clicks.HOUR(click_time))_device_1day',\n",
    "    'MODE(clicks.HOUR(click_time) WHERE is_attributed = True)_device_1day',\n",
    "    'MODE(clicks.ip WHERE is_attributed = True)_os_1day',\n",
    "    'MODE(clicks.app WHERE is_attributed = True)_os_1day',\n",
    "    'MODE(clicks.device WHERE is_attributed = True)_os_1day',\n",
    "    'MODE(clicks.channel WHERE is_attributed = True)_os_1day',\n",
    "    'MODE(clicks.HOUR(click_time))_os_1day',\n",
    "    'MODE(clicks.HOUR(click_time) WHERE is_attributed = True)_os_1day',\n",
    "    'MODE(clicks.ip)_os_1day',\n",
    "    'MODE(clicks.app)_os_1day',\n",
    "    'MODE(clicks.device)_os_1day',\n",
    "    'MODE(clicks.channel)_os_1day',\n",
    "    'MODE(clicks.ip)_channel_1day',\n",
    "    'MODE(clicks.app)_channel_1day',\n",
    "    'MODE(clicks.device)_channel_1day',\n",
    "    'MODE(clicks.os)_channel_1day',\n",
    "]\n",
    "\n",
    "\n",
    "numerical_features = [\n",
    "    'COUNT(clicks)_device_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time WHERE is_attributed = True)_device_1day',\n",
    "    'COUNT(clicks WHERE is_attributed = True)_device_1day',\n",
    "    'PERCENT_TRUE(clicks.is_attributed)_os_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time)_os_1day',\n",
    "    'COUNT(clicks)_os_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time WHERE is_attributed = True)_os_1day',\n",
    "    'COUNT(clicks WHERE is_attributed = True)_os_1day',\n",
    "    'PERCENT_TRUE(clicks.is_attributed)_channel_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time)_channel_1day',\n",
    "    'COUNT(clicks)_channel_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time WHERE is_attributed = True)_channel_1day',\n",
    "    'COUNT(clicks WHERE is_attributed = True)_channel_1day',\n",
    "    'PERCENT_TRUE(clicks.is_attributed)_app_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time)_app_1day',\n",
    "    'COUNT(clicks)_app_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time WHERE is_attributed = True)_app_1day',\n",
    "    'COUNT(clicks WHERE is_attributed = True)_app_1day',\n",
    "    'PERCENT_TRUE(clicks.is_attributed)_device_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time)_device_1day',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_batch(clf, X, y, w):  clf.partial_fit(X, y, sample_weight=w)\n",
    "\n",
    "def predict_batch(clf, X):  return clf.predict(X)\n",
    "\n",
    "def evaluate_batch(clf, X, y, rcount):\n",
    "    auc= roc_auc_score(y, predict_batch(clf, X))\n",
    "    print(rcount, \"ROC AUC:\", auc)\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(f'[{name}] done in {time.time() - t0:.0f} s')\n",
    "\n",
    "def df_add_counts(df, cols):\n",
    "    arr_slice = df[cols].values\n",
    "    unq, unqtags, counts = np.unique(np.ravel_multi_index(arr_slice.T, arr_slice.max(0) + 1),\n",
    "                                     return_inverse=True, return_counts=True)\n",
    "    df[\"_\".join(cols)+'_count'] = counts[unqtags]\n",
    "\n",
    "def df2csr(wb, df, pick_hours=None):\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    with timer(\"Adding counts\"):\n",
    "        df['click_time']= pd.to_datetime(df['click_time'])\n",
    "        dt= df['click_time'].dt\n",
    "        df['day'] = dt.day.astype('uint8')\n",
    "        df['hour'] = dt.hour.astype('uint8')\n",
    "        del(dt)\n",
    "        df_add_counts(df, ['ip', 'day', 'hour'])\n",
    "        df_add_counts(df, ['ip', 'app'])\n",
    "        df_add_counts(df, ['ip', 'app', 'os'])\n",
    "        df_add_counts(df, ['ip', 'device'])\n",
    "        df_add_counts(df, ['app', 'channel'])\n",
    "        #cpuStats()\n",
    "\n",
    "    with timer(\"Adding next click times\"):\n",
    "        D= 2**26\n",
    "        df['category'] = (df['ip'].astype(str) + \"_\" + df['app'].astype(str) + \"_\" + df['device'].astype(str) \\\n",
    "                         + \"_\" + df['os'].astype(str)).apply(hash) % D\n",
    "        click_buffer= np.full(D, 3000000000, dtype=np.uint32)\n",
    "        df['epochtime']= df['click_time'].astype(np.int64) // 10 ** 9\n",
    "        next_clicks= []\n",
    "        for category, time in zip(reversed(df['category'].values), reversed(df['epochtime'].values)):\n",
    "            next_clicks.append(click_buffer[category]-time)\n",
    "            click_buffer[category]= time\n",
    "        del(click_buffer)\n",
    "        df['next_click']= list(reversed(next_clicks))\n",
    "\n",
    "    for fea in ['ip_day_hour_count','ip_app_count','ip_app_os_count','ip_device_count',\n",
    "                'app_channel_count','next_click']:  df[fea]= np.log2(1 + df[fea].values).astype(int)\n",
    "\n",
    "    with timer(\"Generating str_array\"):\n",
    "        str_array= (\"I\" + df['ip'].astype(str) \\\n",
    "            + \" A\" + df['app'].astype(str) \\\n",
    "            + \" D\" + df['device'].astype(str) \\\n",
    "            + \" O\" + df['os'].astype(str) \\\n",
    "            + \" C\" + df['channel'].astype(str) \\\n",
    "            + \" WD\" + df['day'].astype(str) \\\n",
    "            + \" H\" + df['hour'].astype(str) \\\n",
    "            + \" AXC\" + df['app'].astype(str)+\"_\"+df['channel'].astype(str) \\\n",
    "            + \" OXC\" + df['os'].astype(str)+\"_\"+df['channel'].astype(str) \\\n",
    "            + \" AXD\" + df['app'].astype(str)+\"_\"+df['device'].astype(str) \\\n",
    "            + \" IXA\" + df['ip'].astype(str)+\"_\"+df['app'].astype(str) \\\n",
    "            + \" AXO\" + df['app'].astype(str)+\"_\"+df['os'].astype(str) \\\n",
    "            + \" IDHC\" + df['ip_day_hour_count'].astype(str) \\\n",
    "            + \" IAC\" + df['ip_app_count'].astype(str) \\\n",
    "            + \" AOC\" + df['ip_app_os_count'].astype(str) \\\n",
    "            + \" IDC\" + df['ip_device_count'].astype(str) \\\n",
    "            + \" AC\" + df['app_channel_count'].astype(str) \\\n",
    "            + \" NC\" + df['next_click'].astype(str)\n",
    "          ).values\n",
    "    #cpuStats()\n",
    "    if 'is_attributed' in df.columns:\n",
    "        labels = df['is_attributed'].values\n",
    "        weights = np.multiply([1.0 if x == 1 else 0.2 for x in df['is_attributed'].values],\n",
    "                              df['hour'].apply(lambda x: 1.0 if x in pick_hours else 0.5))\n",
    "    else:\n",
    "        labels = []\n",
    "        weights = []\n",
    "    return str_array, labels, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2csr2(wb, df, pick_hours=None):\n",
    "    labels = df['is_attributed'].values\n",
    "    weights = np.multiply([1.0 if x == 1 else 0.2 for x in df['is_attributed'].values], 0.5)\n",
    "    df.drop(columns=['is_attributed'], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    for fea in numerical_features:  df[fea]= np.log2(1 + df[fea].values).astype(int)\n",
    "    \n",
    "    df = df.rename(columns=lambda x: x.replace(\" \", \"_\"))\n",
    "    cols = list(df)\n",
    "    def mkstr(row):\n",
    "        return ' '.join(f\"{c}{v}\" for (c, v) in zip(cols, row))\n",
    "\n",
    "    str_array = df.apply(lambda row: mkstr(row), axis=1, raw=True).values\n",
    "        \n",
    "    return str_array, labels, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 1000000\n",
    "D = 2 ** 25\n",
    "\n",
    "wb = wordbatch.WordBatch(\n",
    "    None, \n",
    "    extractor=(\n",
    "        WordHash, \n",
    "        {\n",
    "            \"ngram_range\": (1, 2), \n",
    "            \"analyzer\": \"word\",\n",
    "            \"lowercase\": False, \n",
    "            \"n_features\": D,\n",
    "            \"norm\": None, \n",
    "            \"binary\": True\n",
    "        }),\n",
    "    minibatch_size=batchsize // 80,\n",
    "    procs=8,\n",
    "    freeze=True,\n",
    "    timeout=1800,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "clf = FM_FTRL(\n",
    "    alpha=0.05,\n",
    "    beta=0.1,\n",
    "    L1=0.0,\n",
    "    L2=0.0,\n",
    "    D=D,\n",
    "    alpha_fm=0.02,\n",
    "    L2_fm=0.0,\n",
    "    init_fm=0.01,\n",
    "    weight_fm=1.0,\n",
    "    D_fm=8,\n",
    "    e_noise=0.0,\n",
    "    iters=3,\n",
    "    inv_link=\"sigmoid\",\n",
    "    e_clip=1.0,\n",
    "    threads=24,\n",
    "    use_avx=1,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = pd.read_csv(validate_filename, engine='c', sep=\",\", dtype=dtypes)\n",
    "str_array_val, labels_val, weights_val = df2csr2(wb, df_val)\n",
    "X_val = wb.transform(str_array_val)\n",
    "del df_val, str_array_val\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Adding counts] done in 1 s\n",
      "[Adding next click times] done in 10 s\n",
      "[Generating str_array] done in 30 s\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for train_filename in train_filenames:\n",
    "    for df_c in pd.read_csv(train_filename, engine='c', chunksize=batchsize, sep=\",\", dtype=dtypes):\n",
    "        with timer(\"df2csr\"):\n",
    "            str_array, labels, weights= df2csr(wb, df_c)\n",
    "        with timer(\"transform\"):\n",
    "            X = wb.transform(str_array)\n",
    "        with timer(\"fit_batch\"):\n",
    "            fit_batch(clf, X, labels, weights)\n",
    "        print(\"Train:\")\n",
    "        with timer(\"evaluate_batch train\"):\n",
    "            evaluate_batch(clf, X, labels, i)\n",
    "        print(\"Test:\")\n",
    "        with timer(\"evaluate_batch test\"):\n",
    "            evaluate_batch(clf, X_val, labels_val, i)\n",
    "        i = i + 1\n",
    "\n",
    "        del df_c, X, str_array\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
