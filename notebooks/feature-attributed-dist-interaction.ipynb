{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import featuretools as ft\n",
    "\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from itertools import combinations\n",
    "\n",
    "from dask import bag\n",
    "from dask.diagnostics import ProgressBar\n",
    "from featuretools.primitives import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_entityset(filename, target_entity):\n",
    "    df = pd.read_hdf(filename)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df['id'] = df.index\n",
    "\n",
    "    es = ft.EntitySet(id='clicks')\n",
    "    es = es.entity_from_dataframe(\n",
    "        entity_id='clicks',\n",
    "        dataframe=df,\n",
    "        index='id',\n",
    "        time_index='click_time',\n",
    "        variable_types={\n",
    "            'ip': ft.variable_types.Categorical,\n",
    "            'app': ft.variable_types.Categorical,\n",
    "            'device': ft.variable_types.Categorical,\n",
    "            'os': ft.variable_types.Categorical,\n",
    "            'channel': ft.variable_types.Categorical,\n",
    "            'is_attributed': ft.variable_types.Boolean,\n",
    "        }\n",
    "    )\n",
    "    es = es.normalize_entity(base_entity_id='clicks', new_entity_id=target_entity, index=target_entity, make_time_index=False)\n",
    "    es = es.normalize_entity(base_entity_id='clicks', new_entity_id='hour', index='hour', make_time_index=False)\n",
    "    es.add_last_time_indexes()\n",
    "    es['clicks']['is_attributed'].interesting_values = [True]\n",
    "    return es\n",
    "\n",
    "def calc_feature_matrix(es, target_entity, cutoff_time, training_window):\n",
    "    feature_matrix, _ = ft.dfs(\n",
    "        entityset=es,\n",
    "        target_entity=target_entity,\n",
    "        trans_primitives=[],\n",
    "        agg_primitives=[Count, PercentTrue, AvgTimeBetween, Skew, Std, Median],\n",
    "        where_primitives=[Count, PercentTrue, AvgTimeBetween],\n",
    "        cutoff_time=cutoff_time,\n",
    "        training_window=training_window,\n",
    "        max_features=-1,\n",
    "        max_depth=3\n",
    "    )\n",
    "\n",
    "    return feature_matrix\n",
    "\n",
    "\n",
    "def create_features(entity_sets, target_entity, cutoff_time, training_window):\n",
    "    tw_suffix = training_window.get_name().replace(' ', '').lower()\n",
    "\n",
    "    feature_matrices = entity_sets.map(\n",
    "        calc_feature_matrix,\n",
    "        target_entity=target_entity,\n",
    "        cutoff_time=cutoff_time,\n",
    "        training_window=training_window)\n",
    "    out = feature_matrices.compute()\n",
    "    feature_matrix = pd.concat(out)\n",
    "#     feature_matrix = feature_matrix[[c for c in feature_matrix.columns if c in to_select]]\n",
    "    feature_matrix.columns = [str(col) + f\"_{target_entity}_{tw_suffix}\" for col in feature_matrix.columns]\n",
    "\n",
    "    del out, feature_matrices\n",
    "    gc.collect()\n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_entities_init = ['app', 'device', 'os', 'channel', 'ip', 'hour']\n",
    "target_entities = []\n",
    "\n",
    "for t in combinations(target_entities_init, 1):\n",
    "#     if 'device' in t: continue\n",
    "    target_entities.append(t[0])\n",
    "for t in combinations(target_entities_init, 2):\n",
    "#     if 'ip' in t: continue\n",
    "    target_entities.append(list(t))\n",
    "for t in combinations(target_entities_init, 3):\n",
    "#     if 'ip' in t: continue\n",
    "    target_entities.append(list(t))\n",
    "# for t in combinations(target_entities_init, 4):\n",
    "#     target_entities.append(list(t))\n",
    "\n",
    "target_entities.remove('device')\n",
    "target_entities.remove(['app', 'ip'])\n",
    "target_entities.remove(['os', 'ip'])\n",
    "target_entities.remove(['channel', 'ip'])\n",
    "target_entities.remove(['app', 'os', 'ip'])\n",
    "target_entities.remove(['app', 'device', 'ip'])\n",
    "target_entities.remove(['app', 'channel', 'ip'])\n",
    "target_entities.remove(['app', 'ip', 'hour'])\n",
    "target_entities.remove(['device', 'os', 'ip'])\n",
    "target_entities.remove(['device', 'channel', 'ip'])\n",
    "target_entities.remove(['device', 'ip', 'hour'])\n",
    "target_entities.remove(['os', 'channel', 'ip'])\n",
    "target_entities.remove(['os', 'ip', 'hour'])\n",
    "target_entities.remove(['channel', 'ip', 'hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['app',\n",
       " 'os',\n",
       " 'channel',\n",
       " 'ip',\n",
       " 'hour',\n",
       " ['app', 'device'],\n",
       " ['app', 'os'],\n",
       " ['app', 'channel'],\n",
       " ['app', 'hour'],\n",
       " ['device', 'os'],\n",
       " ['device', 'channel'],\n",
       " ['device', 'ip'],\n",
       " ['device', 'hour'],\n",
       " ['os', 'channel'],\n",
       " ['os', 'hour'],\n",
       " ['channel', 'hour'],\n",
       " ['ip', 'hour'],\n",
       " ['app', 'device', 'os'],\n",
       " ['app', 'device', 'channel'],\n",
       " ['app', 'device', 'hour'],\n",
       " ['app', 'os', 'channel'],\n",
       " ['app', 'os', 'hour'],\n",
       " ['app', 'channel', 'hour'],\n",
       " ['device', 'os', 'channel'],\n",
       " ['device', 'os', 'hour'],\n",
       " ['device', 'channel', 'hour'],\n",
       " ['os', 'channel', 'hour']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing app_channel_hour\n",
      "Writing ../data/interim/features/app_channel_hour/features_2017-11-08_1700_7day_attributed6.hdf.compress\n",
      "Writing ../data/interim/features/app_channel_hour/features_2017-11-09_1700_7day_attributed6.hdf.compress\n",
      "Processing device_os_channel\n",
      "Writing ../data/interim/features/device_os_channel/features_2017-11-07_1700_7day_attributed6.hdf.compress\n",
      "Writing ../data/interim/features/device_os_channel/features_2017-11-08_1700_7day_attributed6.hdf.compress\n",
      "Writing ../data/interim/features/device_os_channel/features_2017-11-09_1700_7day_attributed6.hdf.compress\n",
      "Processing device_os_hour\n",
      "Writing ../data/interim/features/device_os_hour/features_2017-11-07_1700_7day_attributed6.hdf.compress\n",
      "Writing ../data/interim/features/device_os_hour/features_2017-11-08_1700_7day_attributed6.hdf.compress\n",
      "Writing ../data/interim/features/device_os_hour/features_2017-11-09_1700_7day_attributed6.hdf.compress\n",
      "Processing device_channel_hour\n",
      "Writing ../data/interim/features/device_channel_hour/features_2017-11-07_1700_7day_attributed6.hdf.compress\n",
      "Writing ../data/interim/features/device_channel_hour/features_2017-11-08_1700_7day_attributed6.hdf.compress\n",
      "Writing ../data/interim/features/device_channel_hour/features_2017-11-09_1700_7day_attributed6.hdf.compress\n",
      "Processing os_channel_hour\n",
      "Writing ../data/interim/features/os_channel_hour/features_2017-11-07_1700_7day_attributed6.hdf.compress\n",
      "Writing ../data/interim/features/os_channel_hour/features_2017-11-08_1700_7day_attributed6.hdf.compress\n",
      "Writing ../data/interim/features/os_channel_hour/features_2017-11-09_1700_7day_attributed6.hdf.compress\n"
     ]
    }
   ],
   "source": [
    "# pbar = ProgressBar()\n",
    "# pbar.register()\n",
    "\n",
    "continue_next = False\n",
    "\n",
    "# target_entities = [['channel', 'hour']]\n",
    "feature_name_suffix = 'attributed6'\n",
    "training_windows = ['7 day']\n",
    "cutoff_times= [\n",
    "    datetime.datetime(2017, 11, 7, 17, 0),\n",
    "    datetime.datetime(2017, 11, 8, 17, 0),\n",
    "    datetime.datetime(2017, 11, 9, 17, 0)\n",
    "]\n",
    "\n",
    "for target_entity in target_entities:\n",
    "    if not continue_next:\n",
    "        if target_entity == ['app', 'os', 'hour']:\n",
    "            continue_next = True\n",
    "            continue\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "    target_entity_name = target_entity if type(target_entity) == str else \"_\".join(target_entity)\n",
    "    print(f\"Processing {target_entity_name}\")\n",
    "    features_dir = f\"../data/interim/features/{target_entity_name}\"\n",
    "    if not os.path.exists(features_dir): os.makedirs(features_dir)\n",
    "    filenames = glob(f\"../data/interim/partitioned3/{target_entity_name}/train_*.hdf.compress\")\n",
    "    b = bag.from_sequence(filenames)\n",
    "    entity_sets = b.map(create_entityset, target_entity_name)\n",
    "\n",
    "    for cutoff_time in cutoff_times:\n",
    "        for training_window in training_windows:\n",
    "            tw_suffix = training_window.replace(' ', '').lower()\n",
    "            feature_matrix = create_features(entity_sets, target_entity=target_entity_name, cutoff_time=cutoff_time, training_window=ft.Timedelta(training_window))\n",
    "            output_file = f\"{features_dir}/features_{cutoff_time.strftime('%Y-%m-%d_%H%M')}_{tw_suffix}_{feature_name_suffix}.hdf.compress\"\n",
    "            print(f\"Writing {output_file}\")\n",
    "            feature_matrix.to_hdf(output_file, 'features', mode='w', complib='blosc', fletcher32=True, complevel=9)\n",
    "            del feature_matrix\n",
    "            gc.collect()\n",
    "        \n",
    "    del b, entity_sets\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('../data/interim/features/channel_hour/features_2017-11-09_1700_7day_attributed6.hdf.compress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['COUNT(clicks)_channel_hour_7days',\n",
       "       'PERCENT_TRUE(clicks.is_attributed)_channel_hour_7days',\n",
       "       'AVG_TIME_BETWEEN(clicks.click_time)_channel_hour_7days',\n",
       "       'COUNT(clicks WHERE is_attributed = True)_channel_hour_7days',\n",
       "       'AVG_TIME_BETWEEN(clicks.click_time WHERE is_attributed = True)_channel_hour_7days',\n",
       "       'SKEW(clicks.hour.COUNT(clicks))_channel_hour_7days',\n",
       "       'SKEW(clicks.hour.PERCENT_TRUE(clicks.is_attributed))_channel_hour_7days',\n",
       "       'SKEW(clicks.hour.AVG_TIME_BETWEEN(clicks.click_time))_channel_hour_7days',\n",
       "       'STD(clicks.hour.COUNT(clicks))_channel_hour_7days',\n",
       "       'STD(clicks.hour.PERCENT_TRUE(clicks.is_attributed))_channel_hour_7days',\n",
       "       'STD(clicks.hour.AVG_TIME_BETWEEN(clicks.click_time))_channel_hour_7days',\n",
       "       'MEDIAN(clicks.hour.COUNT(clicks))_channel_hour_7days',\n",
       "       'MEDIAN(clicks.hour.PERCENT_TRUE(clicks.is_attributed))_channel_hour_7days',\n",
       "       'MEDIAN(clicks.hour.AVG_TIME_BETWEEN(clicks.click_time))_channel_hour_7days'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
