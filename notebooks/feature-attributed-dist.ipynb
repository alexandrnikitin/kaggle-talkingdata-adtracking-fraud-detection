{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import featuretools as ft\n",
    "\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "\n",
    "from dask import bag\n",
    "from dask.diagnostics import ProgressBar\n",
    "from featuretools.primitives import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_entityset(filename, target_entity):\n",
    "    df = pd.read_csv(filename, usecols=to_read, dtype=dtypes, parse_dates=to_parse)\n",
    "    df['id'] = df.index\n",
    "\n",
    "    es = ft.EntitySet(id='clicks')\n",
    "    es = es.entity_from_dataframe(\n",
    "        entity_id='clicks',\n",
    "        dataframe=df,\n",
    "        index='id',\n",
    "        time_index='click_time',\n",
    "        variable_types={\n",
    "            'ip': ft.variable_types.Categorical,\n",
    "            'app': ft.variable_types.Categorical,\n",
    "            'device': ft.variable_types.Categorical,\n",
    "            'os': ft.variable_types.Categorical,\n",
    "            'channel': ft.variable_types.Categorical,\n",
    "            'is_attributed': ft.variable_types.Boolean,\n",
    "        }\n",
    "    )\n",
    "    es = es.normalize_entity(base_entity_id='clicks', new_entity_id=target_entity, index=target_entity, make_time_index=False)\n",
    "    es.add_last_time_indexes()\n",
    "    es['clicks']['is_attributed'].interesting_values = [True]\n",
    "    return es\n",
    "\n",
    "def calc_feature_matrix(es, target_entity, cutoff_time, training_window):\n",
    "    feature_matrix, _ = ft.dfs(\n",
    "        entityset=es,\n",
    "        target_entity=target_entity,\n",
    "        trans_primitives=[Hour],\n",
    "        agg_primitives=[PercentTrue, Trend, TimeSinceLast, AvgTimeBetween, Mode, Count],\n",
    "        where_primitives=[Trend, TimeSinceLast, AvgTimeBetween, Mode, Count],\n",
    "        cutoff_time=cutoff_time,\n",
    "        training_window=training_window,\n",
    "        max_features=-1,\n",
    "        max_depth=3\n",
    "    )\n",
    "\n",
    "    return feature_matrix\n",
    "\n",
    "\n",
    "def create_features(entity_sets, target_entity, cutoff_time, training_window):\n",
    "    tw_suffix = training_window.get_name().replace(' ', '').lower()\n",
    "\n",
    "    feature_matrices = entity_sets.map(\n",
    "        calc_feature_matrix,\n",
    "        target_entity=target_entity,\n",
    "        cutoff_time=cutoff_time,\n",
    "        training_window=training_window)\n",
    "    out = feature_matrices.compute()\n",
    "    feature_matrix = pd.concat(out)\n",
    "    feature_matrix = feature_matrix[[c for c in feature_matrix.columns if c in to_select]]\n",
    "    feature_matrix.columns = [str(col) + f\"_{target_entity}_{tw_suffix}\" for col in feature_matrix.columns]\n",
    "\n",
    "    del out, feature_matrices\n",
    "    gc.collect()\n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing channel\n",
      "[########################################] | 100% Completed |  2min 10.7s\n",
      "[########################################] | 100% Completed |  2min 10.8s\n",
      "Writing ../data/interim/features/channel/features_2017-11-08_1700_1day_attributed.csv\n",
      "Processing app\n",
      "[########################################] | 100% Completed |  4min 25.7s\n",
      "[########################################] | 100% Completed |  4min 25.7s\n",
      "Writing ../data/interim/features/app/features_2017-11-08_1700_1day_attributed.csv\n",
      "Processing device\n",
      "[########################################] | 100% Completed | 24min 52.0s\n",
      "[########################################] | 100% Completed | 24min 52.0s\n",
      "Writing ../data/interim/features/device/features_2017-11-08_1700_1day_attributed.csv\n",
      "Processing os\n",
      "[########################################] | 100% Completed |  7min 47.7s\n",
      "[########################################] | 100% Completed |  7min 47.7s\n",
      "Writing ../data/interim/features/os/features_2017-11-08_1700_1day_attributed.csv\n"
     ]
    }
   ],
   "source": [
    "pbar = ProgressBar()\n",
    "pbar.register()\n",
    "\n",
    "feature_name_suffix = 'attributed'\n",
    "target_entities = ['channel', 'app', 'device', 'os']\n",
    "training_windows = ['1 day']\n",
    "cutoff_time=datetime.datetime(2017, 11, 8, 17, 0)\n",
    "train_filename = 'features_2017-11-08_1700'\n",
    "\n",
    "for target_entity in target_entities:\n",
    "    print(f\"Processing {target_entity}\")\n",
    "    features_dir = f\"../data/interim/features/{target_entity}\"\n",
    "    if not os.path.exists(features_dir): os.makedirs(features_dir)\n",
    "    filenames = glob(f\"../data/interim/partitioned/{target_entity}/train_*.csv\")\n",
    "    b = bag.from_sequence(filenames)\n",
    "    entity_sets = b.map(create_entityset, target_entity)\n",
    "\n",
    "    for training_window in training_windows:\n",
    "        tw_suffix = training_window.replace(' ', '').lower()\n",
    "        feature_matrix = create_features(entity_sets, target_entity=target_entity, cutoff_time=cutoff_time, training_window=ft.Timedelta(training_window))\n",
    "        \n",
    "        output_file = f\"{features_dir}/{train_filename}_{tw_suffix}_{feature_name_suffix}.csv\"\n",
    "        print(f\"Writing {output_file}\")\n",
    "        feature_matrix.to_csv(output_file)\n",
    "        del feature_matrix\n",
    "        gc.collect()\n",
    "        \n",
    "    del entity_sets\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
