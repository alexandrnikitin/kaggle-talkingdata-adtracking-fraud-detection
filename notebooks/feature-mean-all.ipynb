{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import featuretools as ft\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from dask import bag\n",
    "from dask.diagnostics import ProgressBar\n",
    "from featuretools.primitives import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '../data/interim/partitioned/channel'\n",
    "input_train_file = '../data/interim/train_2017-11-08_0400.csv'\n",
    "output_train_file = '../data/interim/train_2017-11-08_0400_percent.csv'\n",
    "\n",
    "dtypes = {\n",
    "    'ip': 'uint32',\n",
    "    'app': 'uint16',\n",
    "    'device': 'uint16',\n",
    "    'os': 'uint16',\n",
    "    'channel': 'uint16',\n",
    "    'is_attributed': 'uint8'\n",
    "}\n",
    "to_read = ['app', 'device', 'os', 'channel', 'is_attributed', 'click_time']\n",
    "to_parse = ['click_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = ProgressBar()\n",
    "pbar.register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob(f\"{input_path}/train_*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createEntitySet(filename):\n",
    "    df = pd.read_csv(filename, usecols=to_read, dtype=dtypes, parse_dates=to_parse)\n",
    "    df['id'] = range(len(df))\n",
    "    \n",
    "    es = ft.EntitySet(id='clicks')\n",
    "    es = es.entity_from_dataframe(\n",
    "        entity_id='clicks',\n",
    "        dataframe=df,\n",
    "        index='id',\n",
    "        time_index='click_time',\n",
    "        \n",
    "        variable_types={\n",
    "            'app': ft.variable_types.Categorical,\n",
    "            'device': ft.variable_types.Categorical,\n",
    "            'os': ft.variable_types.Categorical,\n",
    "            'channel': ft.variable_types.Categorical,\n",
    "            'is_attributed': ft.variable_types.Boolean,\n",
    "        }\n",
    "    )\n",
    "\n",
    "#     es = es.normalize_entity(base_entity_id='clicks', new_entity_id='apps', index='app', make_time_index=False)\n",
    "#     es = es.normalize_entity(base_entity_id='clicks', new_entity_id='devices', index='device', make_time_index=False)\n",
    "#     es = es.normalize_entity(base_entity_id='clicks', new_entity_id='oses', index='os', make_time_index=False)\n",
    "    es = es.normalize_entity(base_entity_id='clicks', new_entity_id='channels', index='channel', make_time_index=False)\n",
    "    es.add_last_time_indexes()\n",
    "    return es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = bag.from_sequence(filenames)\n",
    "entity_sets = b.map(createEntitySet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_feature_matrix(es, entity_id, cutoff_time):\n",
    "    feature_matrix, feature_defs = ft.dfs(\n",
    "        entityset=es,\n",
    "        target_entity=entity_id,\n",
    "#         agg_primitives=[PercentTrue],\n",
    "#         trans_primitives=[],\n",
    "        cutoff_time=cutoff_time,\n",
    "        training_window=ft.Timedelta(\"3 hours\"),\n",
    "        max_depth=1)\n",
    "\n",
    "#     feature_matrix.columns = [str(col) + f\"_{entity_id}\" for col in feature_matrix.columns]\n",
    "    return feature_matrix, feature_defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(input_train_file, usecols=to_read, dtype=dtypes, parse_dates=to_parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_time = df_train['click_time'].min()\n",
    "feature_matrices = entity_sets.map(calc_feature_matrix, entity_id='channels', cutoff_time=cutoff_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  3min  5.8s\n"
     ]
    }
   ],
   "source": [
    "out = feature_matrices.compute()\n",
    "_, feature_defs = out[0]\n",
    "feature_matrices = list(map(list, zip(*out)))[0]\n",
    "feature_matrix = pd.concat(feature_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.join(feature_matrix, on='channel')\n",
    "X.drop(columns=['click_time'], inplace=True)\n",
    "X = X.fillna(0)\n",
    "y = X.pop('is_attributed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  9.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AUC 0.95 +/- 0.00'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=400, maxn_jobs=-1)\n",
    "scores = cross_val_score(estimator=clf,X=X, y=y, cv=3, scoring=\"roc_auc\", verbose=True)\n",
    "\n",
    "\"AUC %.2f +/- %.2f\" % (scores.mean(), scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=400, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Feature: app, 0.274\n",
      "2: Feature: PERCENT_TRUE(clicks.is_attributed), 0.224\n",
      "3: Feature: os, 0.131\n",
      "4: Feature: NUM_UNIQUE(clicks.app), 0.082\n",
      "5: Feature: NUM_UNIQUE(clicks.device), 0.074\n",
      "6: Feature: NUM_UNIQUE(clicks.os), 0.055\n",
      "7: Feature: device, 0.044\n",
      "8: Feature: COUNT(clicks), 0.042\n",
      "9: Feature: channel, 0.028\n",
      "10: Feature: MODE(clicks.app), 0.019\n",
      "11: Feature: MODE(clicks.os), 0.017\n",
      "12: Feature: MODE(clicks.device), 0.010\n"
     ]
    }
   ],
   "source": [
    "def feature_importances(model, features, n=10):\n",
    "    importances = model.feature_importances_\n",
    "    zipped = sorted(zip(features, importances), key=lambda x: -x[1])\n",
    "    for i, f in enumerate(zipped[:n]):\n",
    "        print(\"%d: Feature: %s, %.3f\" % (i+1, f[0], f[1]))\n",
    "\n",
    "    return [f[0] for f in zipped[:n]]\n",
    "\n",
    "top_features = feature_importances(clf, X, n=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
