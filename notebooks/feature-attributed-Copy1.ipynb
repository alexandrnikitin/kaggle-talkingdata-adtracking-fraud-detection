{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import featuretools as ft\n",
    "\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "\n",
    "from featuretools.primitives import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('../data/raw/train.hdf.compress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id'] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_entityset(df, target_entity):\n",
    "    es = ft.EntitySet(id='clicks')\n",
    "    es = es.entity_from_dataframe(\n",
    "        entity_id='clicks',\n",
    "        dataframe=df,\n",
    "        index='id',\n",
    "        time_index='click_time',\n",
    "        variable_types={\n",
    "            'ip': ft.variable_types.Categorical,\n",
    "            'app': ft.variable_types.Categorical,\n",
    "            'device': ft.variable_types.Categorical,\n",
    "            'os': ft.variable_types.Categorical,\n",
    "            'channel': ft.variable_types.Categorical,\n",
    "            'is_attributed': ft.variable_types.Boolean,\n",
    "        }\n",
    "    )\n",
    "    es = es.normalize_entity(base_entity_id='clicks', new_entity_id=target_entity, index=target_entity, make_time_index=False)\n",
    "\n",
    "    es.add_last_time_indexes()\n",
    "    es['clicks']['is_attributed'].interesting_values = [True]\n",
    "    return es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_features(entityset, target_entity, cutoff_time, training_window):\n",
    "    feature_matrix, feature_defs = ft.dfs(\n",
    "        entityset=entityset,\n",
    "        target_entity=target_entity,\n",
    "        cutoff_time=cutoff_time,\n",
    "        training_window=training_window,\n",
    "        agg_primitives=[PercentTrue],\n",
    "#         agg_primitives=[PercentTrue, Trend, TimeSinceLast, AvgTimeBetween, Mode],\n",
    "#         where_primitives=[Trend, TimeSinceLast, AvgTimeBetween, Mode],\n",
    "        max_depth=3,\n",
    "#         features_only=True\n",
    "    )\n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing app\n",
      "Creating entity set\n",
      "Creating features\n",
      "Writing ../data/interim/features/app/train_2017-11-07_1700_1day_attributed.hdf.compress\n",
      "Processing device\n",
      "Creating entity set\n",
      "Creating features\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-588556a7ed26>\u001b[0m in \u001b[0;36mcreate_features\u001b[0;34m(entityset, target_entity, cutoff_time, training_window)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#         agg_primitives=[PercentTrue, Trend, TimeSinceLast, AvgTimeBetween, Mode],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#         where_primitives=[Trend, TimeSinceLast, AvgTimeBetween, Mode],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m#         features_only=True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     )\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/featuretools/synthesis/dfs.py\u001b[0m in \u001b[0;36mdfs\u001b[0;34m(entities, relationships, entityset, target_entity, cutoff_time, instance_ids, agg_primitives, trans_primitives, allowed_paths, max_depth, ignore_entities, ignore_variables, seed_features, drop_contains, drop_exact, where_primitives, max_features, cutoff_time_in_index, save_progress, features_only, training_window, approximate, verbose)\u001b[0m\n\u001b[1;32m    190\u001b[0m                                                   \u001b[0mcutoff_time_in_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcutoff_time_in_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                                                   \u001b[0msave_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_progress\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                                                   verbose=verbose)\n\u001b[0m\u001b[1;32m    193\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfeature_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/featuretools/computational_backends/calculate_feature_matrix.py\u001b[0m in \u001b[0;36mcalculate_feature_matrix\u001b[0;34m(features, cutoff_time, instance_ids, entities, relationships, entityset, cutoff_time_in_index, training_window, approximate, save_progress, verbose, backend_verbose, verbose_desc, profile)\u001b[0m\n\u001b[1;32m    194\u001b[0m                                           \u001b[0msave_progress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                                           \u001b[0mno_unapproximated_aggs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcutoff_df_time_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                                           target_time, pass_columns)\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0mfeature_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_feature_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# Do a manual garbage collection in case objects from calculate_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/featuretools/computational_backends/calculate_feature_matrix.py\u001b[0m in \u001b[0;36mcalculate_batch\u001b[0;34m(features, group, approximate, entityset, backend_verbose, training_window, profile, verbose, save_progress, backend, no_unapproximated_aggs, cutoff_df_time_var, target_time, pass_columns)\u001b[0m\n\u001b[1;32m    270\u001b[0m                                        \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                                        \u001b[0mprecalculated_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecalculated_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m                                        training_window=window)\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mid_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_feature_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/featuretools/computational_backends/calculate_feature_matrix.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msave_progress\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pydatetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/featuretools/computational_backends/calculate_feature_matrix.py\u001b[0m in \u001b[0;36mcalc_results\u001b[0;34m(time_last, ids, precalculated_features, training_window)\u001b[0m\n\u001b[1;32m    243\u001b[0m                                                 \u001b[0mignored\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_approx_feature_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                                                 \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m                                                 verbose=backend_verbose)\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/featuretools/computational_backends/pandas_backend.py\u001b[0m in \u001b[0;36mcalculate_all_features\u001b[0;34m(self, instance_ids, time_last, training_window, profile, precalculated_features, ignored, verbose)\u001b[0m\n\u001b[1;32m    103\u001b[0m                                                  \u001b[0mtime_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_last\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                                                  \u001b[0mtraining_window\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_window\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                                                  verbose=verbose)\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mlarge_eframes_by_filter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_full_entity\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/featuretools/entityset/entityset.py\u001b[0m in \u001b[0;36mget_pandas_data_slice\u001b[0;34m(self, filter_entity_ids, index_eid, instances, entity_columns, time_last, training_window, verbose)\u001b[0m\n\u001b[1;32m    212\u001b[0m                         \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchild_columns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                         \u001b[0mtime_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_last\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                         training_window=training_window)\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                 \u001b[0;31m# add link variables to this dataframe in order to link it to its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/featuretools/entityset/entity.py\u001b[0m in \u001b[0;36mquery_by_values\u001b[0;34m(self, instance_vals, variable_id, columns, time_last, training_window, return_sorted, start, end, random_seed, shuffle)\u001b[0m\n\u001b[1;32m    286\u001b[0m                                      \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m                                      \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m                                      random_seed=random_seed)\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mindex_by_parent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent_entity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/featuretools/entityset/entity.py\u001b[0m in \u001b[0;36m_filter_and_sort\u001b[0;34m(self, df, time_last, training_window, columns, sortby, start, end, shuffle, random_seed)\u001b[0m\n\u001b[1;32m    602\u001b[0m                         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mtime_last\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtraining_window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_time_index\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m                             \u001b[0mlti_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_time_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m                             \u001b[0mlti_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlti_slice\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mtime_last\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtraining_window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m                             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mlti_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, index, **kwargs)\u001b[0m\n\u001b[1;32m   2679\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reindex'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2680\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2681\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2683\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fillna'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m         \u001b[0;31m# perform the reindex on the axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3022\u001b[0m         return self._reindex_axes(axes, level, limit, tolerance, method,\n\u001b[0;32m-> 3023\u001b[0;31m                                   fill_value, copy).__finalize__(self)\n\u001b[0m\u001b[1;32m   3024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3025\u001b[0m     def _reindex_axes(self, axes, level, limit, tolerance, method, fill_value,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[0;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[1;32m   3034\u001b[0m             \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3035\u001b[0m             new_index, indexer = ax.reindex(labels, level=level, limit=limit,\n\u001b[0;32m-> 3036\u001b[0;31m                                             tolerance=tolerance, method=method)\n\u001b[0m\u001b[1;32m   3037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3038\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, target, method, level, limit, tolerance)\u001b[0m\n\u001b[1;32m   2985\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2987\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2988\u001b[0m                     indexer = self.get_indexer(target, method=method,\n\u001b[1;32m   2989\u001b[0m                                                \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.cache_readonly.__get__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mis_unique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1316\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m         \u001b[0;34m\"\"\" return if the index has unique values \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1318\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "target_entities = ['app', 'device', 'os', 'channel', 'ip']\n",
    "# target_entities = ['channel']\n",
    "training_windows = ['1 day']\n",
    "cutoff_time=datetime.datetime(2017, 11, 7, 17, 0)\n",
    "\n",
    "for target_entity in target_entities:\n",
    "    print(f\"Processing {target_entity}\")\n",
    "    print(\"Creating entity set\")\n",
    "    es = create_entityset(df, target_entity)\n",
    "    features_dir = f\"../data/interim/features/{target_entity}\"\n",
    "    if not os.path.exists(features_dir): os.makedirs(features_dir)\n",
    "    \n",
    "    for training_window in training_windows:\n",
    "        training_window=ft.Timedelta(training_window)\n",
    "        print(\"Creating features\")\n",
    "        feature_matrix = create_features(es, target_entity=target_entity, cutoff_time=cutoff_time, training_window=training_window)\n",
    "        tw_suffix = training_window.get_name().replace(' ', '').lower()\n",
    "        feature_matrix.columns = [str(col) + f\"_{target_entity}_{tw_suffix}\" for col in feature_matrix.columns]\n",
    "        output_file = f\"{features_dir}/train_2017-11-07_1700_{tw_suffix}_attributed.hdf.compress\"\n",
    "        print(f\"Writing {output_file}\")\n",
    "        feature_matrix.to_hdf(output_file, 'features', mode='w', complib='blosc', fletcher32=True, complevel=9)\n",
    "        del feature_matrix\n",
    "        gc.collect()\n",
    "    del es\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERCENT_TRUE(clicks.is_attributed)_channel_1day</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>channel</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.068773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.068111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.486134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PERCENT_TRUE(clicks.is_attributed)_channel_1day\n",
       "channel                                                 \n",
       "0                                               0.068773\n",
       "3                                               0.000420\n",
       "4                                               0.068111\n",
       "5                                               0.486134\n",
       "13                                              0.000413"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_hdf('../data/interim/features/channel/train_2017-11-07_1700_1day_attributed.hdf.compress').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
