{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import wordbatch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from contextlib import contextmanager\n",
    "from glob import glob\n",
    "from itertools import combinations\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from wordbatch.extractors import WordHash\n",
    "from wordbatch.models import FM_FTRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'ip': 'uint32',\n",
    "    'app': 'uint16',\n",
    "    'device': 'uint16',\n",
    "    'os': 'uint16',\n",
    "    'channel': 'uint16',\n",
    "    'is_attributed': 'uint8'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    'ip', 'app', 'device', 'os', 'channel',\n",
    "]\n",
    "\n",
    "numerical_features_q = [\n",
    "    'PERCENT_TRUE(clicks.is_attributed)_app_1day',\n",
    "    'PERCENT_TRUE(clicks.is_attributed)_device_1day',\n",
    "    'PERCENT_TRUE(clicks.is_attributed)_os_1day',\n",
    "    'PERCENT_TRUE(clicks.is_attributed)_channel_1day',\n",
    "    'PERCENT_TRUE(clicks.is_attributed)_ip_1day',\n",
    "    'PERCENT_TRUE(clicks.is_attributed)_app_device_1day',\n",
    "    'PERCENT_TRUE(clicks.is_attributed)_app_os_1day',\n",
    "    'PERCENT_TRUE(clicks.is_attributed)_app_channel_1day',\n",
    "    'PERCENT_TRUE(clicks.is_attributed)_app_ip_1day',\n",
    "    'PERCENT_TRUE(clicks.is_attributed)_device_os_1day',\n",
    "    'PERCENT_TRUE(clicks.is_attributed)_device_channel_1day',\n",
    "    'PERCENT_TRUE(clicks.is_attributed)_device_ip_1day',\n",
    "    'PERCENT_TRUE(clicks.is_attributed)_os_channel_1day',\n",
    "    'PERCENT_TRUE(clicks.is_attributed)_os_ip_1day',\n",
    "    \n",
    "    'AVG_TIME_BETWEEN(clicks.click_time)_app_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time WHERE is_attributed = True)_app_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time)_device_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time WHERE is_attributed = True)_device_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time)_os_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time WHERE is_attributed = True)_os_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time)_channel_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time WHERE is_attributed = True)_channel_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time)_ip_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time WHERE is_attributed = True)_ip_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time)_app_device_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time WHERE is_attributed = True)_app_device_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time)_app_os_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time WHERE is_attributed = True)_app_os_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time)_app_channel_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time WHERE is_attributed = True)_app_channel_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time)_app_ip_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time WHERE is_attributed = True)_app_ip_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time)_device_os_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time WHERE is_attributed = True)_device_os_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time)_device_channel_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time WHERE is_attributed = True)_device_channel_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time)_device_ip_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time WHERE is_attributed = True)_device_ip_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time)_os_channel_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time WHERE is_attributed = True)_os_channel_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time)_os_ip_1day',\n",
    "    'AVG_TIME_BETWEEN(clicks.click_time WHERE is_attributed = True)_os_ip_1day',\n",
    "]\n",
    "\n",
    "numerical_features_l = []\n",
    "\n",
    "numerical_features = numerical_features_q + numerical_features_l\n",
    "\n",
    "interaction_features = [\n",
    "    ['app', 'channel'],\n",
    "    ['app', 'device'],\n",
    "    ['app', 'os'],\n",
    "    ['os', 'channel'],\n",
    "    ['ip', 'app'],\n",
    "#     ['device', 'PERCENT_TRUE(clicks.is_attributed)_device_1day'],\n",
    "#     ['app', 'PERCENT_TRUE(clicks.is_attributed)_app_1day'],\n",
    "#     ['os', 'PERCENT_TRUE(clicks.is_attributed)_os_1day'],\n",
    "#     ['channel', 'PERCENT_TRUE(clicks.is_attributed)_channel_1day'],\n",
    "    \n",
    "#     ['device', 'COUNT(clicks)_device_1day'],\n",
    "#     ['app', 'COUNT(clicks)_app_1day'],\n",
    "#     ['os', 'COUNT(clicks)_os_1day'],\n",
    "#     ['channel', 'COUNT(clicks)_channel_1day'],\n",
    "    \n",
    "#     ['device', 'COUNT(clicks WHERE is_attributed = True)_device_1day'],\n",
    "#     ['app', 'COUNT(clicks WHERE is_attributed = True)_app_1day'],\n",
    "#     ['os', 'COUNT(clicks WHERE is_attributed = True)_os_1day'],\n",
    "#     ['channel', 'COUNT(clicks WHERE is_attributed = True)_channel_1day'],\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_entities_init = ['app', 'device', 'os', 'channel', 'ip']\n",
    "target_entities = []\n",
    "\n",
    "for t in combinations(target_entities_init, 1):\n",
    "    target_entities.append(t[0])\n",
    "for t in combinations(target_entities_init, 2):\n",
    "    target_entities.append(list(t))\n",
    "# for t in combinations(target_entities_init, 3):\n",
    "#     target_entities.append(list(t))\n",
    "# for t in combinations(target_entities_init, 4):\n",
    "#     target_entities.append(list(t))\n",
    "\n",
    "target_entities.remove(['channel', 'ip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df, target_entity):\n",
    "    if type(target_entity) == str:\n",
    "        df[target_entity] = df.index\n",
    "    else:\n",
    "        df[target_entity[0]], df[target_entity[1]] = df.index.str.split('_', 1).str\n",
    "        df[target_entity[0]] = df[target_entity[0]].astype(dtypes[target_entity[0]])\n",
    "        df[target_entity[1]] = df[target_entity[1]].astype(dtypes[target_entity[1]])\n",
    "    return df\n",
    "\n",
    "def combine_features(df, features_prefix, feature_suffix):\n",
    "    for target_entity in target_entities:\n",
    "        target_entity_name = target_entity if type(target_entity) == str else \"_\".join(target_entity)\n",
    "        feature_files = sorted(glob(f\"../data/interim/features/{target_entity_name}/{features_prefix}*{feature_suffix}.hdf.compress\"))\n",
    "        assert len(feature_files) > 0\n",
    "        for feature_file in feature_files:\n",
    "            df_feature = pd.read_hdf(feature_file)\n",
    "            df_feature = split(df_feature, target_entity)\n",
    "            df = pd.merge(df, df_feature, how='left', left_on=target_entity, right_on=target_entity)\n",
    "            del df_feature\n",
    "            gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train cache doesn't exist\n",
      "Validation cache doesn't exist\n"
     ]
    }
   ],
   "source": [
    "cache_train = '../data/cache/train_wordbatch.hdf.compress'\n",
    "if not Path(cache_train).exists():\n",
    "    print(\"Train cache doesn't exist, creating\")\n",
    "    df_train = pd.read_hdf('../data/interim/downsampled/train_2017-11-07_1700_08_1600_0.hdf.compress')\n",
    "    df_train = combine_features(df_train, 'features_2017-11-07_1700', 'attributed2')\n",
    "    df_train.to_hdf(cache_train, 'train', mode='w', complib='blosc', fletcher32=True, complevel=9)\n",
    "else:\n",
    "    df_train = pd.read_hdf(cache_train)\n",
    "\n",
    "cache_val = '../data/cache/validate_wordbatch.hdf.compress'\n",
    "if not Path(cache_val).exists():\n",
    "    print(\"Validation cache doesn't exist, creating\")\n",
    "    train_summary = pd.read_csv('../data/interim/day_hour_train.csv')\n",
    "    val_start_row = train_summary[(train_summary['day'] == 9) & (train_summary['hour'] == 4)]['start'].values[0]\n",
    "    val_stop_row = train_summary[(train_summary['day'] == 9) & (train_summary['hour'] == 4)]['end'].values[0]\n",
    "    df_val = pd.read_hdf('../data/raw/train.hdf.compress', start=val_start_row, stop=val_stop_row)\n",
    "    df_val = combine_features(df_val, 'features_2017-11-08_1700', 'attributed2')\n",
    "    df_val.to_hdf(cache_val, 'train', mode='w', complib='blosc', fletcher32=True, complevel=9)\n",
    "else:\n",
    "    df_val = pd.read_hdf(cache_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(f'[{name}] done in {time.time() - t0:.0f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 2 ** 25\n",
    "\n",
    "wb = wordbatch.WordBatch(\n",
    "    None, \n",
    "    extractor=(\n",
    "        WordHash, \n",
    "        {\n",
    "            \"ngram_range\": (1, 1), \n",
    "            \"analyzer\": \"word\",\n",
    "            \"lowercase\": False, \n",
    "            \"n_features\": D,\n",
    "            \"norm\": None, \n",
    "            \"binary\": True\n",
    "        }),\n",
    "#     minibatch_size=batchsize // 80,\n",
    "#     method='threading',\n",
    "    procs=24,\n",
    "    freeze=True,\n",
    "    timeout=1800,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "clf = FM_FTRL(\n",
    "    alpha=0.05,\n",
    "    beta=0.1,\n",
    "    L1=0.0,\n",
    "    L2=0.0,\n",
    "    D=D,\n",
    "    alpha_fm=0.02,\n",
    "    L2_fm=0.0,\n",
    "    init_fm=0.01,\n",
    "    weight_fm=1.0,\n",
    "    D_fm=8,\n",
    "    e_noise=0.0,\n",
    "    iters=3,\n",
    "    inv_link=\"sigmoid\",\n",
    "    e_clip=1.0,\n",
    "    threads=24,\n",
    "    use_avx=1,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize(df):\n",
    "    for c in numerical_features_q:\n",
    "        df[c] = pd.qcut(df[c], 10, labels=False, duplicates='drop')\n",
    "    for c in numerical_features_l:\n",
    "        df[c] = pd.qcut(df[c], 100, labels=False, duplicates='drop')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2csr3(df):\n",
    "    df = df.fillna(0)\n",
    "    df = discretize(df)\n",
    "\n",
    "    for i, c in enumerate(categorical_features):\n",
    "        name = f\"C_{i}_\"\n",
    "        df[name] = name + df[c].astype(str) + \" \"\n",
    "\n",
    "    for i, c in enumerate(numerical_features):\n",
    "        name = f\"N_{i}_\"\n",
    "        df[name] = name + df[c].astype(str) + \" \"\n",
    "\n",
    "    for i, (c1, c2) in enumerate(interaction_features):\n",
    "        name = f\"X_{i}_\"\n",
    "        df[name] = name + df[c1].astype(str) + \"_\" + df[c2].astype(str) + \" \"\n",
    "\n",
    "    cols = [c for c in df.columns if c.startswith(('C_', 'N_', 'X_'))]\n",
    "    return df[cols].sum(axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df):\n",
    "    y = df.pop('is_attributed')\n",
    "    w = np.multiply([1.0 if x == 1 else 0.2 for x in y], 1)\n",
    "    str_array = df2csr3(df)\n",
    "    X = wb.transform(str_array)\n",
    "    del df, str_array\n",
    "    gc.collect()\n",
    "    return X, y, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 7s, sys: 3min 4s, total: 9min 11s\n",
      "Wall time: 9min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_val, y_val, _ = process_data(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[data] done in 210 s\n",
      "[partial_fit] done in 1010 s\n",
      "ROC AUC: 0.9533677302628775\n",
      "[evaluate_batch test] done in 402 s\n",
      "[partial_fit] done in 587 s\n",
      "ROC AUC: 0.9533886980782357\n",
      "[evaluate_batch test] done in 325 s\n"
     ]
    }
   ],
   "source": [
    "with timer(\"data\"):\n",
    "    X_train, y_train, w_train = process_data(df_train)\n",
    "\n",
    "del df_train, df_val\n",
    "gc.collect()\n",
    "    \n",
    "for epoch in range(0, 11, 1):\n",
    "    with timer(\"partial_fit\"):\n",
    "        clf.partial_fit(X_train, y_train, sample_weight=w_train)\n",
    "    with timer(\"evaluate_batch test\"):\n",
    "        print(\"ROC AUC:\", roc_auc_score(y_val, clf.predict(X_val)))\n",
    "\n",
    "\n",
    "del X_train, y_train, w_train\n",
    "gc.collect()\n",
    "    \n",
    "del X_val, y_val\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
